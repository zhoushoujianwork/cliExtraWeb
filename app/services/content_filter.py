"""
å¯¹è¯å†…å®¹è¿‡æ»¤å™¨
ç”¨äºæ¸…ç†Q CLIè¾“å‡ºï¼Œåªä¿ç•™å®é™…çš„AIå›å¤å†…å®¹
"""
import re
from typing import List, Dict, Any

class ContentFilter:
    """å†…å®¹è¿‡æ»¤å™¨"""
    
    def __init__(self):
        # Q CLIç•Œé¢å…ƒç´ çš„æ­£åˆ™è¡¨è¾¾å¼
        self.ui_patterns = [
            # ASCIIè‰ºæœ¯å’Œè£…é¥°
            r'^[â €-â£¿\s]*$',  # Brailleå­—ç¬¦
            r'^[â•­â•®â•¯â•°â”€â”‚â”Œâ”â””â”˜â”œâ”¤â”¬â”´â”¼â”â”ƒâ”â”“â”—â”›â”£â”«â”³â”»â•‹â•â•‘â•”â•—â•šâ•â• â•£â•¦â•©â•¬]+.*$',  # æ¡†çº¿å­—ç¬¦
            r'^[â–€â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–‰â–Šâ–‹â–Œâ–â–â–â–â–‘â–’â–“â–”â–•â––â–—â–˜â–™â–šâ–›â–œâ–â–â–Ÿ]+.*$',  # å—å­—ç¬¦
            
            # Q CLIæç¤ºä¿¡æ¯
            r'.*Did you know\?.*',
            r'.*You can execute bash commands.*',
            r'.*ctrl \+ j new lines.*',
            r'.*\/help all commands.*',
            r'.*All tools are now trusted.*',
            r'.*Agents can sometimes do unexpected things.*',
            r'.*Learn more at https:\/\/docs\.aws\.amazon\.com.*',
            r'.*ğŸ¤– You are chatting with.*',
            r'.*Picking up where we left off.*',
            
            # æ—¶é—´æˆ³å’Œæ§åˆ¶å­—ç¬¦
            r'^\[.*\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}.*\]$',
            r'^.*\[\d+G.*$',  # å…‰æ ‡æ§åˆ¶
            r'^.*\?\d+[hl].*$',  # ç»ˆç«¯æ§åˆ¶åºåˆ—
            
            # ç©ºè¡Œå’Œçº¯ç©ºç™½
            r'^\s*$',
            
            # ANSIè½¬ä¹‰åºåˆ—æ®‹ç•™
            r'^[\x1b\[\d;]*[mK]*$',
        ]
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ä»¥æé«˜æ€§èƒ½
        self.compiled_patterns = [re.compile(pattern, re.IGNORECASE) for pattern in self.ui_patterns]
    
    def clean_content(self, raw_content: str) -> str:
        """
        æ¸…ç†åŸå§‹å†…å®¹ï¼Œåªä¿ç•™å®é™…çš„AIå›å¤
        
        Args:
            raw_content: åŸå§‹å†…å®¹
            
        Returns:
            æ¸…ç†åçš„å†…å®¹
        """
        if not raw_content:
            return ""
        
        lines = raw_content.split('\n')
        cleaned_lines = []
        
        for line in lines:
            # ç§»é™¤ANSIè½¬ä¹‰åºåˆ—
            clean_line = self._remove_ansi_sequences(line)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯UIå…ƒç´ 
            if not self._is_ui_element(clean_line):
                # è¿›ä¸€æ­¥æ¸…ç†å†…å®¹
                processed_line = self._process_content_line(clean_line)
                if processed_line.strip():
                    cleaned_lines.append(processed_line)
        
        # åˆå¹¶è¿ç»­çš„ç©ºè¡Œ
        result = self._merge_empty_lines('\n'.join(cleaned_lines))
        
        # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºè¡Œ
        return result.strip()
    
    def _remove_ansi_sequences(self, text: str) -> str:
        """ç§»é™¤ANSIè½¬ä¹‰åºåˆ—"""
        # ç§»é™¤ANSIé¢œè‰²å’Œæ§åˆ¶åºåˆ—
        ansi_pattern = re.compile(r'\x1b\[[0-9;]*[mK]')
        text = ansi_pattern.sub('', text)
        
        # ç§»é™¤å…¶ä»–æ§åˆ¶å­—ç¬¦
        control_pattern = re.compile(r'\x1b\[[?]?\d*[hl]')
        text = control_pattern.sub('', text)
        
        return text
    
    def _is_ui_element(self, line: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯UIå…ƒç´ """
        for pattern in self.compiled_patterns:
            if pattern.match(line):
                return True
        return False
    
    def _process_content_line(self, line: str) -> str:
        """å¤„ç†å†…å®¹è¡Œ"""
        # ç§»é™¤è¡Œé¦–çš„ç‰¹æ®Šå­—ç¬¦ï¼ˆå¦‚ > æç¤ºç¬¦ï¼‰
        line = re.sub(r'^[\s>]*', '', line)
        
        # ç§»é™¤è¡Œå°¾çš„æ§åˆ¶å­—ç¬¦
        line = re.sub(r'[\x00-\x1f\x7f-\x9f]*$', '', line)
        
        return line
    
    def parse_conversation(self, raw_content: str) -> List[Dict[str, Any]]:
        """
        è§£æå¯¹è¯å†…å®¹ï¼ŒåŒºåˆ†AIè¾“å‡ºå’Œç”¨æˆ·è¾“å…¥
        
        Args:
            raw_content: åŸå§‹å†…å®¹
            
        Returns:
            å¯¹è¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« type, content, timestamp
        """
        if not raw_content:
            return []
        
        lines = raw_content.split('\n')
        conversations = []
        current_message = {
            'type': None,
            'content': '',
            'timestamp': None,
            'raw_lines': []
        }
        
        for line in lines:
            # æ¸…ç†ANSIåºåˆ—
            clean_line = self._remove_ansi_sequences(line)
            
            # æ£€æµ‹å‘è¨€è€…æ ‡è¯†
            speaker_info = self._detect_speaker(clean_line)
            
            if speaker_info:
                # ä¿å­˜ä¹‹å‰çš„æ¶ˆæ¯
                if current_message['type'] and current_message['content'].strip():
                    conversations.append({
                        'type': current_message['type'],
                        'content': current_message['content'].strip(),
                        'timestamp': current_message['timestamp'] or self._extract_timestamp(line),
                        'raw_content': '\n'.join(current_message['raw_lines'])
                    })
                
                # å¼€å§‹æ–°æ¶ˆæ¯
                current_message = {
                    'type': speaker_info['type'],
                    'content': speaker_info['content'],
                    'timestamp': speaker_info['timestamp'] or self._extract_timestamp(line),
                    'raw_lines': [line]
                }
            elif current_message['type'] and self._is_message_continuation(clean_line):
                # ç»§ç»­å½“å‰æ¶ˆæ¯
                current_message['content'] += '\n' + clean_line
                current_message['raw_lines'].append(line)
            elif current_message['type']:
                # æ¶ˆæ¯ç»“æŸï¼Œä¿å­˜å½“å‰æ¶ˆæ¯
                if current_message['content'].strip():
                    conversations.append({
                        'type': current_message['type'],
                        'content': current_message['content'].strip(),
                        'timestamp': current_message['timestamp'],
                        'raw_content': '\n'.join(current_message['raw_lines'])
                    })
                current_message = {'type': None, 'content': '', 'timestamp': None, 'raw_lines': []}
        
        # ä¿å­˜æœ€åä¸€æ¡æ¶ˆæ¯
        if current_message['type'] and current_message['content'].strip():
            conversations.append({
                'type': current_message['type'],
                'content': current_message['content'].strip(),
                'timestamp': current_message['timestamp'],
                'raw_content': '\n'.join(current_message['raw_lines'])
            })
        
        return self._filter_conversations(conversations)
    
    def _detect_speaker(self, line: str) -> Dict[str, Any]:
        """
        æ£€æµ‹å‘è¨€è€…ç±»å‹
        
        Args:
            line: æ¸…ç†åçš„è¡Œå†…å®¹
            
        Returns:
            å‘è¨€è€…ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å« type, content, timestamp
        """
        # ç”¨æˆ·è¾“å…¥æ ‡è¯†ï¼š!> å¼€å¤´
        user_patterns = [
            r'^!>\s*(.*)$',                     # !> ç”¨æˆ·è¾“å…¥
            r'^User:\s*(.*)$',                  # User: æ ¼å¼
            r'^ä½ :\s*(.*)$',                    # ä¸­æ–‡ç”¨æˆ·æ ‡è¯†
            r'^Question:\s*(.*)$',              # Question: æ ¼å¼
            r'^>\s+(.+)$'                       # > åé¢è·Ÿå†…å®¹ï¼ˆç”¨æˆ·è¾“å…¥ï¼‰
        ]
        
        # AIè¾“å‡ºæ ‡è¯†ï¼š> å¼€å¤´ï¼ˆä½†ä¸æ˜¯ç”¨æˆ·è¾“å…¥ï¼‰
        ai_patterns = [
            r'^>\s*$',                          # å•ç‹¬çš„ > ï¼ˆAIå¼€å§‹å“åº”ï¼‰
            r'^>\[0m\s*(.*)$',                  # >[0m AIå“åº”
            r'^Assistant:\s*(.*)$',             # Assistant: æ ¼å¼
            r'^AI:\s*(.*)$',                    # AI: æ ¼å¼
            r'^å›ç­”:\s*(.*)$',                  # ä¸­æ–‡å›ç­”æ ‡è¯†
            r'^Answer:\s*(.*)$'                 # Answer: æ ¼å¼
        ]
        
        # ç³»ç»Ÿæ¶ˆæ¯æ ‡è¯†
        system_patterns = [
            r'^System:\s*(.*)$',                # System: æ ¼å¼
            r'^ç³»ç»Ÿ:\s*(.*)$',                  # ä¸­æ–‡ç³»ç»Ÿæ ‡è¯†
            r'^\[ç³»ç»Ÿ\]\s*(.*)$',               # [ç³»ç»Ÿ] æ ¼å¼
            r'^\[INFO\]\s*(.*)$',               # [INFO] æ ¼å¼
            r'^\[ERROR\]\s*(.*)$'               # [ERROR] æ ¼å¼
        ]
        
        # æ£€æµ‹ç”¨æˆ·è¾“å…¥
        for pattern in user_patterns:
            match = re.match(pattern, line)
            if match:
                return {
                    'type': 'user',
                    'content': match.group(1).strip() if match.group(1) else '',
                    'timestamp': self._extract_timestamp(line)
                }
        
        # æ£€æµ‹AIè¾“å‡º
        for pattern in ai_patterns:
            match = re.match(pattern, line)
            if match:
                return {
                    'type': 'assistant',
                    'content': match.group(1).strip() if len(match.groups()) > 0 and match.group(1) else '',
                    'timestamp': self._extract_timestamp(line)
                }
        
        # æ£€æµ‹ç³»ç»Ÿæ¶ˆæ¯
        for pattern in system_patterns:
            match = re.match(pattern, line)
            if match:
                return {
                    'type': 'system',
                    'content': match.group(1).strip() if match.group(1) else '',
                    'timestamp': self._extract_timestamp(line)
                }
        
        return None
    
    def _is_message_continuation(self, line: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºæ¶ˆæ¯ç»§ç»­è¡Œ
        
        Args:
            line: æ¸…ç†åçš„è¡Œå†…å®¹
            
        Returns:
            æ˜¯å¦ä¸ºæ¶ˆæ¯ç»§ç»­
        """
        # æ’é™¤æ˜æ˜¾çš„åˆ†éš”ç¬¦å’Œç³»ç»Ÿä¿¡æ¯
        exclude_patterns = [
            r'^=+$',                            # ç­‰å·åˆ†éš”ç¬¦
            r'^-+$',                            # å‡å·åˆ†éš”ç¬¦
            r'^\[.*\]$',                        # æ–¹æ‹¬å·åŒ…å›´çš„ç³»ç»Ÿä¿¡æ¯
            r'Thinking\.\.\.',                  # Thinking... (å®Œå…¨åŒ¹é…)
            r'Loading\.\.\.',                   # Loading... (å®Œå…¨åŒ¹é…)
            r'^\d{4}-\d{2}-\d{2}',             # æ—¥æœŸæ ¼å¼
            r'^\d{2}:\d{2}:\d{2}',             # æ—¶é—´æ ¼å¼
            r'^[>!>]\s*',                       # æ–°çš„å‘è¨€è€…æ ‡è¯†
            r'^(User|Assistant|AI|System|ä½ |å›ç­”|ç³»ç»Ÿ):\s*'  # è§’è‰²æ ‡è¯†
        ]
        
        for pattern in exclude_patterns:
            if re.match(pattern, line):
                return False
        
        return line.strip() != ''
    
    def _extract_timestamp(self, line: str) -> str:
        """
        ä»è¡Œä¸­æå–æ—¶é—´æˆ³
        
        Args:
            line: åŸå§‹è¡Œå†…å®¹
            
        Returns:
            æ—¶é—´æˆ³å­—ç¬¦ä¸²
        """
        # åŒ¹é…å¸¸è§çš„æ—¶é—´æ ¼å¼
        time_patterns = [
            r'(\d{2}:\d{2}:\d{2})',             # HH:MM:SS
            r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})',  # YYYY-MM-DD HH:MM:SS
            r'\[(\d{2}:\d{2}:\d{2})\]'          # [HH:MM:SS]
        ]
        
        for pattern in time_patterns:
            match = re.search(pattern, line)
            if match:
                return match.group(1)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ—¶é—´æˆ³ï¼Œè¿”å›å½“å‰æ—¶é—´
        from datetime import datetime
        return datetime.now().strftime('%H:%M:%S')
    
    def _filter_conversations(self, conversations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        è¿‡æ»¤å’Œæ¸…ç†å¯¹è¯åˆ—è¡¨
        
        Args:
            conversations: åŸå§‹å¯¹è¯åˆ—è¡¨
            
        Returns:
            è¿‡æ»¤åçš„å¯¹è¯åˆ—è¡¨
        """
        filtered = []
        
        for conv in conversations:
            # è¿‡æ»¤æ‰å¤ªçŸ­çš„æ¶ˆæ¯
            if len(conv['content']) < 2:
                continue
            
            # è¿‡æ»¤æ‰çº¯ç³»ç»Ÿå™ªéŸ³
            system_noise = [
                'Thinking...',
                'Loading...',
                'Please wait...',
                'è¯·ç¨ç­‰...',
                'hi',
                '...'
            ]
            
            if any(noise in conv['content'] for noise in system_noise):
                continue
            
            # æ¸…ç†å†…å®¹
            conv['content'] = self._clean_conversation_content(conv['content'])
            
            # æ·»åŠ å¤„ç†æ ‡è®°
            conv['needs_rich_text'] = self._needs_rich_text_rendering(conv['content'])
            conv['id'] = f"{conv['type']}_{len(filtered)}_{hash(conv['content']) % 10000}"
            
            filtered.append(conv)
        
        return filtered
    
    def _clean_conversation_content(self, content: str) -> str:
        """
        æ¸…ç†å¯¹è¯å†…å®¹
        
        Args:
            content: åŸå§‹å†…å®¹
            
        Returns:
            æ¸…ç†åçš„å†…å®¹
        """
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
        content = re.sub(r'\n\s*\n\s*\n+', '\n\n', content)
        
        # ç§»é™¤è¡Œé¦–çš„æç¤ºç¬¦æ®‹ç•™
        lines = content.split('\n')
        cleaned_lines = []
        
        for line in lines:
            # ç§»é™¤è¡Œé¦–çš„ > æˆ– !> æ®‹ç•™
            line = re.sub(r'^[>!]+\s*', '', line)
            cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines).strip()
    
    def _needs_rich_text_rendering(self, content: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦å¯Œæ–‡æœ¬æ¸²æŸ“
        
        Args:
            content: å†…å®¹
            
        Returns:
            æ˜¯å¦éœ€è¦å¯Œæ–‡æœ¬æ¸²æŸ“
        """
        rich_text_indicators = [
            '```',              # ä»£ç å—
            '![',               # å›¾ç‰‡
            '**',               # ç²—ä½“
            '*',                # æ–œä½“
            '#',                # æ ‡é¢˜
            '- ',               # åˆ—è¡¨
            '1. ',              # ç¼–å·åˆ—è¡¨
            'âœ…', 'âŒ', 'âš ï¸',   # çŠ¶æ€å›¾æ ‡
            'http://',          # é“¾æ¥
            'https://'          # é“¾æ¥
        ]
        
        return any(indicator in content for indicator in rich_text_indicators)
    
    def extract_code_blocks(self, content: str) -> List[Dict[str, Any]]:
        """
        æå–ä»£ç å—
        
        Args:
            content: å†…å®¹
            
        Returns:
            ä»£ç å—åˆ—è¡¨
        """
        code_blocks = []
        
        # åŒ¹é…ä»£ç å—
        code_pattern = re.compile(r'```(\w+)?\n(.*?)\n```', re.DOTALL)
        matches = code_pattern.finditer(content)
        
        for match in matches:
            language = match.group(1) or 'text'
            code = match.group(2)
            code_blocks.append({
                'language': language,
                'code': code,
                'start': match.start(),
                'end': match.end()
            })
        
        return code_blocks
    
    def format_for_display(self, content: str) -> str:
        """
        æ ¼å¼åŒ–å†…å®¹ç”¨äºæ˜¾ç¤º
        
        Args:
            content: æ¸…ç†åçš„å†…å®¹
            
        Returns:
            æ ¼å¼åŒ–åçš„å†…å®¹
        """
        if not content:
            return ""
        
        # è‡ªåŠ¨æ£€æµ‹å’Œæ ¼å¼åŒ–ä»£ç å—
        content = self._auto_format_code_blocks(content)
        
        # æ ¼å¼åŒ–åˆ—è¡¨
        content = self._format_lists(content)
        
        # æ ¼å¼åŒ–é“¾æ¥
        content = self._format_links(content)
        
        return content
    
    def _auto_format_code_blocks(self, content: str) -> str:
        """è‡ªåŠ¨æ ¼å¼åŒ–ä»£ç å—"""
        lines = content.split('\n')
        formatted_lines = []
        in_code_block = False
        code_lines = []
        
        for line in lines:
            # æ£€æµ‹ä»£ç è¡Œï¼ˆä»¥ç‰¹å®šå­—ç¬¦å¼€å¤´æˆ–åŒ…å«å‘½ä»¤ï¼‰
            if self._looks_like_code(line) and not in_code_block:
                if code_lines:
                    # ç»“æŸä¹‹å‰çš„ä»£ç å—
                    formatted_lines.append('```bash')
                    formatted_lines.extend(code_lines)
                    formatted_lines.append('```')
                    code_lines = []
                
                in_code_block = True
                code_lines.append(line)
            elif in_code_block and (self._looks_like_code(line) or line.strip() == ''):
                code_lines.append(line)
            else:
                if in_code_block:
                    # ç»“æŸä»£ç å—
                    formatted_lines.append('```bash')
                    formatted_lines.extend(code_lines)
                    formatted_lines.append('```')
                    code_lines = []
                    in_code_block = False
                
                formatted_lines.append(line)
        
        # å¤„ç†æœ€åçš„ä»£ç å—
        if in_code_block and code_lines:
            formatted_lines.append('```bash')
            formatted_lines.extend(code_lines)
            formatted_lines.append('```')
        
        return '\n'.join(formatted_lines)
    
    def _looks_like_code(self, line: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åƒä»£ç è¡Œ"""
        code_indicators = [
            r'^\s*[/$#>]\s+',  # å‘½ä»¤æç¤ºç¬¦
            r'^\s*\w+\s*=',    # å˜é‡èµ‹å€¼
            r'^\s*function\s+', # å‡½æ•°å®šä¹‰
            r'^\s*if\s+',      # æ¡ä»¶è¯­å¥
            r'^\s*for\s+',     # å¾ªç¯è¯­å¥
            r'^\s*while\s+',   # å¾ªç¯è¯­å¥
            r'^\s*echo\s+',    # echoå‘½ä»¤
            r'^\s*cd\s+',      # cdå‘½ä»¤
            r'^\s*ls\s+',      # lså‘½ä»¤
            r'^\s*grep\s+',    # grepå‘½ä»¤
            r'^\s*awk\s+',     # awkå‘½ä»¤
            r'^\s*sed\s+',     # sedå‘½ä»¤
        ]
        
        for pattern in code_indicators:
            if re.match(pattern, line):
                return True
        
        return False
    
    def _format_lists(self, content: str) -> str:
        """æ ¼å¼åŒ–åˆ—è¡¨"""
        # å°† â€¢ è½¬æ¢ä¸º -
        content = re.sub(r'^\s*â€¢\s+', '- ', content, flags=re.MULTILINE)
        return content
    
    def _format_links(self, content: str) -> str:
        """æ ¼å¼åŒ–é“¾æ¥"""
        # è‡ªåŠ¨è½¬æ¢URLä¸ºMarkdowné“¾æ¥
        url_pattern = re.compile(r'(https?://[^\s]+)')
        content = url_pattern.sub(r'[\1](\1)', content)
        return content

# åˆ›å»ºå…¨å±€å®ä¾‹
content_filter = ContentFilter()
